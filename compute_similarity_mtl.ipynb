{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b440d16d-9b02-4e25-8f8c-64799c295fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_and_prepare_behav(subj_num, behav_base_path):\n",
    "    behav_path = f\"{behav_base_path}/sub{subj_num:02d}_behav.tsv\"\n",
    "    behav_df = pd.read_csv(behav_path, sep='\\t')\n",
    "    \n",
    "    # Create cumulative fmri_index per session (0 to 749)\n",
    "    behav_df['fmri_index'] = None\n",
    "    for session in behav_df['SESSION'].unique():\n",
    "        idxs = behav_df[behav_df['SESSION'] == session].index\n",
    "        behav_df.loc[idxs, 'fmri_index'] = range(len(idxs))\n",
    "    behav_df['fmri_index'] = behav_df['fmri_index'].astype(int)\n",
    "    \n",
    "    print(f\"Subject {subj_num}: Loaded behav with {len(behav_df)} rows\")\n",
    "    return behav_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "88d30bf7-3726-42dc-b393-a9761c242c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shared_trials_by_phase(behav_df):\n",
    "    \"\"\"\n",
    "    Filter for shared1000 images and classify trials into encoding/retrieval phases.\n",
    "    \n",
    "    Returns:\n",
    "        - encoding_df: DataFrame for encoding trials\n",
    "        - retrieval1_df: DataFrame for first retrieval\n",
    "        - retrieval2_df: DataFrame for second retrieval (if present)\n",
    "    \"\"\"\n",
    "    # Keep only images that have a repNum entry (i.e., from shared1000 set)\n",
    "    shared_df = behav_df[behav_df[\"shared1000_repNum\"].notna()].copy()\n",
    "    shared_df[\"shared1000_repNum\"] = shared_df[\"shared1000_repNum\"].astype(int)\n",
    "\n",
    "    # Sanity check: each image ID (73KID) should occur at least twice\n",
    "    image_counts = shared_df[\"73KID\"].value_counts()\n",
    "    valid_ids = image_counts[image_counts != 0].index\n",
    "    shared_df = shared_df[shared_df[\"73KID\"].isin(valid_ids)]\n",
    "\n",
    "    # Label trial phase\n",
    "    phase_map = {1: \"encoding\", 2: \"retrieval1\", 3: \"retrieval2\"}\n",
    "    shared_df[\"PHASE\"] = shared_df[\"shared1000_repNum\"].map(phase_map)\n",
    "\n",
    "    # Now split by phase\n",
    "    encoding_df = shared_df[shared_df[\"PHASE\"] == \"encoding\"]\n",
    "    retrieval1_df = shared_df[shared_df[\"PHASE\"] == \"retrieval1\"]\n",
    "    retrieval2_df = shared_df[shared_df[\"PHASE\"] == \"retrieval2\"]\n",
    "\n",
    "    return encoding_df, retrieval1_df, retrieval2_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee12f448-eda6-4487-adaf-4241f0001c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_phase_maps_for_session(behav_df, session_num):\n",
    "#     behav_sess = behav_df[behav_df['SESSION'] == session_num]\n",
    "#     encoding_df, retrieval1_df, retrieval2_df = get_shared_trials_by_phase(behav_sess)\n",
    "\n",
    "#     enc_kids = set(encoding_df['73KID'])\n",
    "#     ret1_kids = set(retrieval1_df['73KID'])\n",
    "#     ret2_kids = set(retrieval2_df['73KID'])\n",
    "#     common_kids_sess = enc_kids & ret1_kids & ret2_kids\n",
    "\n",
    "#     enc_map = dict(zip(encoding_df['73KID'], encoding_df['fmri_index']))\n",
    "#     ret1_map = dict(zip(retrieval1_df['73KID'], retrieval1_df['fmri_index']))\n",
    "#     ret2_map = dict(zip(retrieval2_df['73KID'], retrieval2_df['fmri_index']))\n",
    "\n",
    "#     print(f\"Session {session_num}: {len(common_kids_sess)} common trials across phases\")\n",
    "#     return common_kids_sess, enc_map, ret1_map, ret2_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b96eac7c-3618-4a0d-ba05-7865ab8bc003",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_global_phase_maps(behav_df):\n",
    "    \"\"\"\n",
    "    Match encoding and retrieval trials for shared1000 images across all sessions.\n",
    "\n",
    "    Returns:\n",
    "        - List of dicts: one per image with phase-to-(session, index, button, presentation_type) mapping\n",
    "    \"\"\"\n",
    "    shared_df = behav_df[behav_df[\"shared1000_repNum\"].notna()].copy()\n",
    "    shared_df[\"shared1000_repNum\"] = shared_df[\"shared1000_repNum\"].astype(int)\n",
    "\n",
    "    # # Keep images with all 3 phases\n",
    "    # counts = shared_df.groupby(\"73KID\")[\"shared1000_repNum\"].nunique()\n",
    "    # valid_kids = counts[counts == 3].index\n",
    "    # shared_df = shared_df[shared_df[\"73KID\"].isin(valid_kids)]\n",
    "\n",
    "    # Keep images that appear more than once (i.e., at least 2 phases)\n",
    "    counts = shared_df.groupby(\"73KID\")[\"shared1000_repNum\"].nunique()\n",
    "    valid_kids = counts[counts > 1].index\n",
    "\n",
    "\n",
    "    # Phase mapping\n",
    "    phase_map = {1: \"enc\", 2: \"ret1\", 3: \"ret2\"}\n",
    "    shared_df[\"PHASE\"] = shared_df[\"shared1000_repNum\"].map(phase_map)\n",
    "\n",
    "    image_trials = []\n",
    "    for kid in valid_kids:\n",
    "        rows = shared_df[shared_df[\"73KID\"] == kid]\n",
    "        phase_dict = {\"73KID\": kid}\n",
    "        for _, row in rows.iterrows():\n",
    "            phase = row[\"PHASE\"]\n",
    "            phase_dict[f\"{phase}_session\"] = row[\"SESSION\"]\n",
    "            phase_dict[f\"{phase}_index\"] = row[\"fmri_index\"]\n",
    "            phase_dict[f\"{phase}_button\"] = row[\"BUTTON\"]\n",
    "            phase_dict[f\"{phase}_presentation_type\"] = row[\"presentation_type\"]\n",
    "        image_trials.append(phase_dict)\n",
    "\n",
    "    return image_trials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "701e7b25-9ad4-498d-8240-a72ac19fb47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "def run_subject_pipeline(subj_num, behav_base_path, h5_base_path, roi_map=None):\n",
    "    print(f\"\\n--- Running pipeline for Subject {subj_num} ---\")\n",
    "    \n",
    "    behav_df = load_and_prepare_behav(subj_num, behav_base_path)\n",
    "    h5_path = f\"{h5_base_path}/subj{subj_num:02d}_all_mtl_sessions.h5\"\n",
    "    \n",
    "    similarity_results = []\n",
    "    \n",
    "    with h5py.File(h5_path, 'r') as f:\n",
    "        # Get global matched trials across all sessions/phases\n",
    "        global_phase_list = get_global_phase_maps(behav_df)\n",
    "\n",
    "        # For convenience: list all sessions and rois in the file\n",
    "        available_sessions = list(f.keys())\n",
    "        print(f\"Subject {subj_num}: Found {len(available_sessions)} sessions in HDF5\")\n",
    "        \n",
    "        for trial in global_phase_list:\n",
    "            kid = trial[\"73KID\"]\n",
    "            \n",
    "            # For each phase, get session and index\n",
    "            enc_sess = trial.get(\"enc_session\")\n",
    "            enc_idx = trial.get(\"enc_index\")\n",
    "            ret1_sess = trial.get(\"ret1_session\")\n",
    "            ret1_idx = trial.get(\"ret1_index\")\n",
    "            ret2_sess = trial.get(\"ret2_session\")\n",
    "            ret2_idx = trial.get(\"ret2_index\")\n",
    "\n",
    "            # Skip trials with missing session info\n",
    "            if None in [enc_sess, ret1_sess, ret2_sess, enc_idx, ret1_idx, ret2_idx]:\n",
    "                continue\n",
    "\n",
    "            # Skip if any session not in HDF5 (just to be safe)\n",
    "            if not all(str(s) in available_sessions for s in [f\"session{enc_sess:02d}\", f\"session{ret1_sess:02d}\", f\"session{ret2_sess:02d}\"]):\n",
    "                continue\n",
    "            \n",
    "            # Iterate ROIs from encoding session (assuming same ROIs in all sessions)\n",
    "            roi_names = list(f[f\"session{enc_sess:02d}\"].keys())\n",
    "\n",
    "            for roi in roi_names:\n",
    "                roi_name = roi.split(\"_\", 1)[1] if roi.startswith(\"roi_\") else roi\n",
    "\n",
    "                try:\n",
    "                    enc_beta = f[f\"session{enc_sess:02d}\"][roi][enc_idx, :]\n",
    "                    ret1_beta = f[f\"session{ret1_sess:02d}\"][roi][ret1_idx, :]\n",
    "                    ret2_beta = f[f\"session{ret2_sess:02d}\"][roi][ret2_idx, :]\n",
    "                except Exception:\n",
    "                    # If indexing fails, skip\n",
    "                    continue\n",
    "                \n",
    "                # sim_enc_ret1 = cosine_sim(enc_beta, ret1_beta)\n",
    "                # sim_enc_ret2 = cosine_sim(enc_beta, ret2_beta)\n",
    "                # sim_ret1_ret2 = cosine_sim(ret1_beta, ret2_beta)\n",
    "\n",
    "                # Skip if any vector has zero variance (Pearson correlation is undefined)\n",
    "                if np.std(enc_beta) == 0 or np.std(ret1_beta) == 0 or np.std(ret2_beta) == 0:\n",
    "                    continue\n",
    "                \n",
    "                sim_enc_ret1, _ = pearsonr(enc_beta, ret1_beta)\n",
    "                sim_enc_ret2, _ = pearsonr(enc_beta, ret2_beta)\n",
    "                sim_ret1_ret2, _ = pearsonr(ret1_beta, ret2_beta)\n",
    "\n",
    "\n",
    "                similarity_results.append({\n",
    "                    \"SUBJECT\": subj_num,\n",
    "                    \"73KID\": kid,\n",
    "                    \"ROI\": roi_map.get(roi_name, roi_name) if roi_map else roi_name,\n",
    "                    \"enc_session\": enc_sess,\n",
    "                    \"ret1_session\": ret1_sess,\n",
    "                    \"ret2_session\": ret2_sess,\n",
    "                    \"enc_index\": enc_idx,\n",
    "                    \"ret1_index\": ret1_idx,\n",
    "                    \"ret2_index\": ret2_idx,\n",
    "                    \"enc_ret1\": sim_enc_ret1,\n",
    "                    \"enc_ret2\": sim_enc_ret2,\n",
    "                    \"ret1_ret2\": sim_ret1_ret2,\n",
    "                    # Optional: add button and presentation_type from trial dict if you want\n",
    "                    \"enc_BUTTON\": trial.get(\"enc_button\"),\n",
    "                    \"ret1_BUTTON\": trial.get(\"ret1_button\"),\n",
    "                    \"ret2_BUTTON\": trial.get(\"ret2_button\"),\n",
    "                    \"enc_presentation_type\": trial.get(\"enc_presentation_type\"),\n",
    "                    \"ret1_presentation_type\": trial.get(\"ret1_presentation_type\"),\n",
    "                    \"ret2_presentation_type\": trial.get(\"ret2_presentation_type\"),\n",
    "                })\n",
    "    \n",
    "    similarity_df = pd.DataFrame(similarity_results)\n",
    "    print(f\"Subject {subj_num}: Computed similarities for {len(similarity_df)} trials\")\n",
    "\n",
    "    # out_csv = f\"{h5_base_path}/subj{subj_num:02d}_similarity_results.csv\"\n",
    "    # similarity_df.to_csv(out_csv, index=False)\n",
    "    # print(f\"Subject {subj_num}: Results saved to {out_csv}\")\n",
    "    \n",
    "    return similarity_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d416072b-a7b7-4458-93b1-2fcfccbfe844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import h5py\n",
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# def cosine_sim(vec1, vec2):\n",
    "#     return cosine_similarity(vec1.reshape(1, -1), vec2.reshape(1, -1))[0][0]\n",
    "\n",
    "# def run_subject_pipeline(subj_num, behav_base_path, h5_base_path):\n",
    "#     print(f\"\\n--- Running pipeline for Subject {subj_num} ---\")\n",
    "    \n",
    "#     behav_df = load_and_prepare_behav(subj_num, behav_base_path)\n",
    "#     h5_path = f\"{h5_base_path}/subj{subj_num:02d}_all_mtl_sessions.h5\"\n",
    "    \n",
    "#     similarity_results = []\n",
    "    \n",
    "#     with h5py.File(h5_path, 'r') as f:\n",
    "#         sessions = list(f.keys())\n",
    "#         print(f\"Subject {subj_num}: Found {len(sessions)} sessions in HDF5\")\n",
    "        \n",
    "#         for session in sessions:\n",
    "#             session_num = int(session[-2:])\n",
    "            \n",
    "#             common_kids, enc_map, ret1_map, ret2_map = get_phase_maps_for_session(behav_df, session_num)\n",
    "#             roi_names = list(f[session].keys())\n",
    "            \n",
    "#             for roi in roi_names:\n",
    "#                 roi_data = f[session][roi]\n",
    "                \n",
    "#                 for kid in common_kids:\n",
    "#                     try:\n",
    "#                         enc_idx = enc_map[kid]\n",
    "#                         ret1_idx = ret1_map[kid]\n",
    "#                         ret2_idx = ret2_map[kid]\n",
    "\n",
    "#                         enc_beta = roi_data[enc_idx, :]\n",
    "#                         ret1_beta = roi_data[ret1_idx, :]\n",
    "#                         ret2_beta = roi_data[ret2_idx, :]\n",
    "\n",
    "#                         sim_enc_ret1 = cosine_sim(enc_beta, ret1_beta)\n",
    "#                         sim_enc_ret2 = cosine_sim(enc_beta, ret2_beta)\n",
    "#                         sim_ret1_ret2 = cosine_sim(ret1_beta, ret2_beta)\n",
    "\n",
    "#                         similarity_results.append({\n",
    "#                             'SUBJECT': subj_num,\n",
    "#                             'SESSION': session_num,\n",
    "#                             '73KID': kid,\n",
    "#                             'ROI': roi,\n",
    "#                             'enc_ret1': sim_enc_ret1,\n",
    "#                             'enc_ret2': sim_enc_ret2,\n",
    "#                             'ret1_ret2': sim_ret1_ret2\n",
    "#                         })\n",
    "#                     except KeyError:\n",
    "#                         continue\n",
    "\n",
    "#     similarity_df = pd.DataFrame(similarity_results)\n",
    "#     print(f\"Subject {subj_num}: Computed similarities for {len(similarity_df)} trials\")\n",
    "    \n",
    "#     # Save to CSV\n",
    "#     out_csv = f\"{h5_base_path}/subj{subj_num:02d}_similarity_results.csv\"\n",
    "#     similarity_df.to_csv(out_csv, index=False)\n",
    "#     print(f\"Subject {subj_num}: Results saved to {out_csv}\")\n",
    "    \n",
    "#     return similarity_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "001a22ae-0bc0-484b-bf07-6ce35d2e93fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def cosine_sim(vec1, vec2):\n",
    "    return cosine_similarity(vec1.reshape(1, -1), vec2.reshape(1, -1))[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0335db3d-6b96-4653-b13a-3bd5a8f20e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running pipeline for Subject 1 ---\n",
      "Subject 1: Loaded behav with 30000 rows\n",
      "Subject 1: Found 40 sessions in HDF5\n",
      "Subject 1: Computed similarities for 10000 trials\n",
      "\n",
      "--- Running pipeline for Subject 2 ---\n",
      "Subject 2: Loaded behav with 30000 rows\n",
      "Subject 2: Found 40 sessions in HDF5\n",
      "Subject 2: Computed similarities for 10000 trials\n",
      "\n",
      "--- Running pipeline for Subject 3 ---\n",
      "Subject 3: Loaded behav with 24000 rows\n",
      "Subject 3: Found 32 sessions in HDF5\n",
      "Subject 3: Computed similarities for 6140 trials\n",
      "\n",
      "--- Running pipeline for Subject 4 ---\n",
      "Subject 4: Loaded behav with 22500 rows\n",
      "Subject 4: Found 30 sessions in HDF5\n",
      "Subject 4: Computed similarities for 5150 trials\n",
      "\n",
      "--- Running pipeline for Subject 5 ---\n",
      "Subject 5: Loaded behav with 30000 rows\n",
      "Subject 5: Found 40 sessions in HDF5\n",
      "Subject 5: Computed similarities for 10000 trials\n",
      "\n",
      "--- Running pipeline for Subject 6 ---\n",
      "Subject 6: Loaded behav with 24000 rows\n",
      "Subject 6: Found 32 sessions in HDF5\n",
      "Subject 6: Computed similarities for 6140 trials\n",
      "\n",
      "--- Running pipeline for Subject 7 ---\n",
      "Subject 7: Loaded behav with 30000 rows\n",
      "Subject 7: Found 40 sessions in HDF5\n",
      "Subject 7: Computed similarities for 10000 trials\n",
      "\n",
      "--- Running pipeline for Subject 8 ---\n",
      "Subject 8: Loaded behav with 22500 rows\n",
      "Subject 8: Found 30 sessions in HDF5\n",
      "Subject 8: Computed similarities for 5150 trials\n",
      "Combined results saved to /home/jovyan/cache/memoryNSD/all1-3_subjects_similarity_results.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "behav_base_path = \"/home/jovyan/cache/memoryNSD\"\n",
    "h5_base_path = \"/home/jovyan/cache/memoryNSD\"\n",
    "# os.makedirs(behav_base_path, exist_ok=True)\n",
    "# os.makedirs(h5_base_path, exist_ok=True)\n",
    "\n",
    "# for subj in range(4,9):  # add all your subjects here\n",
    "#     df = run_subject_pipeline(subj, behav_base_path, h5_base_path)\n",
    "import pandas as pd\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for subj in range(1, 9):\n",
    "    df = run_subject_pipeline(subj, behav_base_path, h5_base_path)\n",
    "    all_results.append(df)\n",
    "\n",
    "combined_df = pd.concat(all_results, ignore_index=True)\n",
    "\n",
    "combined_out_csv = f\"{h5_base_path}/all1-3_subjects_similarity_results.csv\"\n",
    "combined_df.to_csv(combined_out_csv, index=False)\n",
    "print(f\"Combined results saved to {combined_out_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ab02eb5e-f931-476f-b656-06e007c4ca86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /home/jovyan/cache/memoryNSD/all1-3_subjects_similarity_results.csv ...\n",
      "Updated ROI labels saved to /home/jovyan/cache/memoryNSD/all1-3_subjects_similarity_results.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def update_roi_labels_in_file(csv_file, roi_map):\n",
    "    print(f\"Processing {csv_file} ...\")\n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    # Convert ROI column to string so it matches the mapping keys\n",
    "    df['ROI'] = df['ROI'].astype(str).map(roi_map).fillna(df['ROI'])\n",
    "\n",
    "    df.to_csv(csv_file, index=False)\n",
    "    print(f\"Updated ROI labels saved to {csv_file}\")\n",
    "\n",
    "# Your string-keyed ROI map\n",
    "roi_map = {\n",
    "    '1': 'ERC',\n",
    "    '2': '35',\n",
    "    '3': '36',\n",
    "    '4': 'SUB',\n",
    "    '5': 'CA1',\n",
    "    '6': 'CA2',\n",
    "    '7': 'CA3',\n",
    "    '8': 'DG',\n",
    "    '9': 'PHC',\n",
    "    '10': 'HT'\n",
    "}\n",
    "\n",
    "combined_csv_path = \"/home/jovyan/cache/memoryNSD/all1-3_subjects_similarity_results.csv\"\n",
    "update_roi_labels_in_file(combined_csv_path, roi_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5578a591-52d6-4b1b-bfe9-a028dceba475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names: ['SUBJECT', '73KID', 'ROI', 'enc_session', 'ret1_session', 'ret2_session', 'enc_index', 'ret1_index', 'ret2_index', 'enc_ret1', 'enc_ret2', 'ret1_ret2', 'enc_BUTTON', 'ret1_BUTTON', 'ret2_BUTTON', 'enc_presentation_type', 'ret1_presentation_type', 'ret2_presentation_type']\n",
      "\n",
      "Sample rows:\n",
      "   SUBJECT  73KID  ROI  enc_session  ret1_session  ret2_session  enc_index  \\\n",
      "0        1   2951  ERC            4            13            37        365   \n",
      "1        1   2951   HT            4            13            37        365   \n",
      "2        1   2951   35            4            13            37        365   \n",
      "3        1   2951   36            4            13            37        365   \n",
      "4        1   2951  SUB            4            13            37        365   \n",
      "\n",
      "   ret1_index  ret2_index  enc_ret1  enc_ret2  ret1_ret2  enc_BUTTON  \\\n",
      "0         715         565  0.023881  0.008184   0.036706         1.0   \n",
      "1         715         565 -0.040522 -0.044279  -0.124554         1.0   \n",
      "2         715         565 -0.033101 -0.087458   0.106534         1.0   \n",
      "3         715         565  0.029230 -0.044402   0.130171         1.0   \n",
      "4         715         565  0.012123 -0.045886   0.003061         1.0   \n",
      "\n",
      "   ret1_BUTTON  ret2_BUTTON enc_presentation_type ret1_presentation_type  \\\n",
      "0          1.0          2.0                   new                   hard   \n",
      "1          1.0          2.0                   new                   hard   \n",
      "2          1.0          2.0                   new                   hard   \n",
      "3          1.0          2.0                   new                   hard   \n",
      "4          1.0          2.0                   new                   hard   \n",
      "\n",
      "  ret2_presentation_type  \n",
      "0                   hard  \n",
      "1                   hard  \n",
      "2                   hard  \n",
      "3                   hard  \n",
      "4                   hard  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV\n",
    "csv_path = \"/home/jovyan/cache/memoryNSD/all1-3_subjects_similarity_results.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Show the column names and a few rows\n",
    "print(\"Column names:\", df.columns.tolist())\n",
    "print(\"\\nSample rows:\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "977d25f3-9bf1-41f2-81f5-2a0ee67485fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique image IDs per subject:\n",
      "SUBJECT\n",
      "1    1000\n",
      "2    1000\n",
      "3     614\n",
      "4     515\n",
      "5    1000\n",
      "6     614\n",
      "7    1000\n",
      "8     515\n",
      "Name: 73KID, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "unique_ids_per_subject = df.groupby(\"SUBJECT\")[\"73KID\"].nunique()\n",
    "print(\"Unique image IDs per subject:\")\n",
    "print(unique_ids_per_subject)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1b944a48-49e5-42a8-bea6-61b2151efdf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 1: Missing 9 sessions -> ['session1', 'session2', 'session3', 'session4', 'session5', 'session6', 'session7', 'session8', 'session9']\n",
      "Subject 2: Missing 9 sessions -> ['session1', 'session2', 'session3', 'session4', 'session5', 'session6', 'session7', 'session8', 'session9']\n",
      "Subject 3: Missing 17 sessions -> ['session1', 'session2', 'session3', 'session4', 'session5', 'session6', 'session7', 'session8', 'session9', 'session33', 'session34', 'session35', 'session36', 'session37', 'session38', 'session39', 'session40']\n",
      "Subject 4: Missing 19 sessions -> ['session1', 'session2', 'session3', 'session4', 'session5', 'session6', 'session7', 'session8', 'session9', 'session31', 'session32', 'session33', 'session34', 'session35', 'session36', 'session37', 'session38', 'session39', 'session40']\n",
      "Subject 5: Missing 9 sessions -> ['session1', 'session2', 'session3', 'session4', 'session5', 'session6', 'session7', 'session8', 'session9']\n",
      "Subject 6: Missing 17 sessions -> ['session1', 'session2', 'session3', 'session4', 'session5', 'session6', 'session7', 'session8', 'session9', 'session33', 'session34', 'session35', 'session36', 'session37', 'session38', 'session39', 'session40']\n",
      "Subject 7: Missing 9 sessions -> ['session1', 'session2', 'session3', 'session4', 'session5', 'session6', 'session7', 'session8', 'session9']\n",
      "Subject 8: Missing 19 sessions -> ['session1', 'session2', 'session3', 'session4', 'session5', 'session6', 'session7', 'session8', 'session9', 'session31', 'session32', 'session33', 'session34', 'session35', 'session36', 'session37', 'session38', 'session39', 'session40']\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import os\n",
    "\n",
    "def check_missing_sessions(h5_base_path, subjects=range(1, 9), expected_sessions=range(1, 41)):\n",
    "    for subj in subjects:\n",
    "        h5_path = os.path.join(h5_base_path, f\"subj{subj:02d}_all_mtl_sessions.h5\")\n",
    "        if not os.path.exists(h5_path):\n",
    "            print(f\"Subject {subj}: HDF5 file not found.\")\n",
    "            continue\n",
    "\n",
    "        with h5py.File(h5_path, \"r\") as f:\n",
    "            available_sessions = set(f.keys())\n",
    "            missing = [f\"session{s}\" for s in expected_sessions if f\"session{s}\" not in available_sessions]\n",
    "\n",
    "            if missing:\n",
    "                print(f\"Subject {subj}: Missing {len(missing)} sessions -> {missing}\")\n",
    "            else:\n",
    "                print(f\"Subject {subj}: All sessions present ✅\")\n",
    "\n",
    "# Run the check\n",
    "check_missing_sessions(\"/home/jovyan/cache/memoryNSD\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2f8686-8ac0-4bdc-9c0c-21c48221b1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sub01.h5 - [sessions][roi1_10][n_trials][mv activation ~ N_Voxels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48834e7d-c288-4164-a5ea-0c80d35fddec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#roi 1 = [n_trials] [0.2 0.5 0.9 .... (n_voxels)]\n",
    "\n",
    "#[n_voxels - 1D] * [n_voxels - 1D]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
